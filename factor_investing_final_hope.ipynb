{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229fd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42f471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b36bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_og = pd.read_csv(\"data_index.csv\")\n",
    "factor_df = pd.read_pickle('factor_pkl.pkl')\n",
    "data_bind = pd.read_pickle('data_bind.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8989e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목코드</th>\n",
       "      <th>종목명</th>\n",
       "      <th>SEC_NM_KOR</th>\n",
       "      <th>ROE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>CFO</th>\n",
       "      <th>DY</th>\n",
       "      <th>PBR</th>\n",
       "      <th>PCR</th>\n",
       "      <th>PER</th>\n",
       "      <th>PRS</th>\n",
       "      <th>12M</th>\n",
       "      <th>K_ratio</th>\n",
       "      <th>z_quality</th>\n",
       "      <th>z_value</th>\n",
       "      <th>z_momentum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000020</td>\n",
       "      <td>동화약품</td>\n",
       "      <td>건강관리</td>\n",
       "      <td>0.019096</td>\n",
       "      <td>0.403956</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.7508</td>\n",
       "      <td>10.8503</td>\n",
       "      <td>9.8295</td>\n",
       "      <td>0.7956</td>\n",
       "      <td>0.088362</td>\n",
       "      <td>4.591582</td>\n",
       "      <td>-2.851032</td>\n",
       "      <td>-5.060231</td>\n",
       "      <td>-1.195162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000040</td>\n",
       "      <td>KR모터스</td>\n",
       "      <td>경기관련소비재</td>\n",
       "      <td>-0.090473</td>\n",
       "      <td>0.091691</td>\n",
       "      <td>-0.025470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5097</td>\n",
       "      <td>-0.044800</td>\n",
       "      <td>-12.228206</td>\n",
       "      <td>3.757001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000050</td>\n",
       "      <td>경방</td>\n",
       "      <td>경기관련소비재</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>0.083892</td>\n",
       "      <td>0.022571</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.3551</td>\n",
       "      <td>9.4324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>-0.284921</td>\n",
       "      <td>-61.718542</td>\n",
       "      <td>2.433971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.066039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000070</td>\n",
       "      <td>삼양홀딩스</td>\n",
       "      <td>소재</td>\n",
       "      <td>0.008454</td>\n",
       "      <td>0.113031</td>\n",
       "      <td>0.033151</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>4.0565</td>\n",
       "      <td>7.1790</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>24.482365</td>\n",
       "      <td>0.431092</td>\n",
       "      <td>-5.677451</td>\n",
       "      <td>-1.500552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000080</td>\n",
       "      <td>하이트진로</td>\n",
       "      <td>필수소비재</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.317866</td>\n",
       "      <td>-0.029284</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>1.2817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2967</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>-0.327817</td>\n",
       "      <td>-76.759593</td>\n",
       "      <td>-0.928571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>456040</td>\n",
       "      <td>OCI</td>\n",
       "      <td>소재</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>456490</td>\n",
       "      <td>교보14호스팩</td>\n",
       "      <td>금융</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>457190</td>\n",
       "      <td>이수스페셜티케미컬</td>\n",
       "      <td>소재</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>460850</td>\n",
       "      <td>동국씨엠</td>\n",
       "      <td>소재</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>460860</td>\n",
       "      <td>동국제강</td>\n",
       "      <td>소재</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        종목코드        종목명 SEC_NM_KOR       ROE       GPA       CFO      DY  \\\n",
       "0     000020       동화약품       건강관리  0.019096  0.403956  0.055600  0.0178   \n",
       "1     000040      KR모터스    경기관련소비재 -0.090473  0.091691 -0.025470     NaN   \n",
       "2     000050         경방    경기관련소비재 -0.004805  0.083892  0.022571  0.0127   \n",
       "3     000070      삼양홀딩스         소재  0.008454  0.113031  0.033151  0.0493   \n",
       "4     000080      하이트진로      필수소비재  0.015787  0.317866 -0.029284  0.0458   \n",
       "...      ...        ...        ...       ...       ...       ...     ...   \n",
       "2393  456040        OCI         소재       NaN       NaN       NaN     NaN   \n",
       "2394  456490    교보14호스팩         금융       NaN       NaN       NaN     NaN   \n",
       "2395  457190  이수스페셜티케미컬         소재       NaN       NaN       NaN     NaN   \n",
       "2396  460850       동국씨엠         소재       NaN       NaN       NaN     NaN   \n",
       "2397  460860       동국제강         소재       NaN       NaN       NaN     NaN   \n",
       "\n",
       "         PBR      PCR      PER     PRS       12M    K_ratio  z_quality  \\\n",
       "0     0.7508  10.8503   9.8295  0.7956  0.088362   4.591582  -2.851032   \n",
       "1     1.2765      NaN      NaN  0.5097 -0.044800 -12.228206   3.757001   \n",
       "2     0.3551   9.4324      NaN  0.7027 -0.284921 -61.718542   2.433971   \n",
       "3     0.2428   4.0565   7.1790  0.1848  0.062500  24.482365   0.431092   \n",
       "4     1.2817      NaN  20.2967  0.5781 -0.327817 -76.759593  -0.928571   \n",
       "...      ...      ...      ...     ...       ...        ...        ...   \n",
       "2393     NaN      NaN      NaN     NaN       NaN        NaN        NaN   \n",
       "2394     NaN      NaN      NaN     NaN       NaN        NaN        NaN   \n",
       "2395     NaN      NaN      NaN     NaN       NaN        NaN        NaN   \n",
       "2396     NaN      NaN      NaN     NaN       NaN        NaN        NaN   \n",
       "2397     NaN      NaN      NaN     NaN       NaN        NaN        NaN   \n",
       "\n",
       "       z_value  z_momentum  \n",
       "0    -5.060231   -1.195162  \n",
       "1          NaN    0.333471  \n",
       "2          NaN    3.066039  \n",
       "3    -5.677451   -1.500552  \n",
       "4          NaN         NaN  \n",
       "...        ...         ...  \n",
       "2393       NaN         NaN  \n",
       "2394       NaN         NaN  \n",
       "2395       NaN         NaN  \n",
       "2396       NaN         NaN  \n",
       "2397       NaN         NaN  \n",
       "\n",
       "[2398 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849156f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og[4000::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdd2bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4977f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('날짜', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ff410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per = df.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815c7be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_per.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0a20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment1:\n",
    "    \"\"\"\n",
    "    차트 데이터는 우선 간단하게 종가와 거래량만 제공한다.\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    30일 데이터를 한꺼번에 넣은 다음 가중치를 출력한다. \n",
    "    \"\"\"\n",
    "    \n",
    "    PRICE_IDX = 0  # 종가의 위치\n",
    "    VOLUME_IDX = 1 # 거래량의 위치\n",
    "    \"\"\"\n",
    "    version0: 아직 차트데이터에 가격밖에 없는 버전. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, chart_data_df , feature_per_stock, factor_df = factor_df, data_bind = data_bind,balance=0, reward_method=\"return\"):\n",
    "        \"\"\"\n",
    "        chart data is n stocks that selected to portfolio\n",
    "        \"\"\"\n",
    "        self.chart_data_df = chart_data_df                                    # type(chart_data) == pd.DataFrame\n",
    "        self.feature_per_stock = feature_per_stock                      # feature per stock (i.e. close/volume)\n",
    "        self.stock_num = int(chart_data_df.shape[1] / self.feature_per_stock)   # num of stock selected for portfolio\n",
    "        self.idx = 0                                                    # index init\n",
    "        self.state = chart_data_df.iloc[self.idx:self.idx+50]                          # state : Vector of the weight of the portfolio\n",
    "#         self.next_state =   chart_data_df.iloc[self.idx+20:self.idx+40]                 # next state\n",
    "        self.reward_method = reward_method                              # set method of reward   \n",
    "        #self.init_vector = np.full(self.stock_num, 1/self.stock_num)    # set init_vector of weights \n",
    "        #self.factor_value = sum(self.state*self.init_vector)        # Portfolio growth compared to the previous day\n",
    "        #self.factor_value_list = [self.portfolio_value]\n",
    "        self.factor_df = factor_df\n",
    "        self.data_bind = data_bind\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        initialize the all weights of portfolios equally\n",
    "        \"\"\"\n",
    "        self.idx = 0                              # index init\n",
    "        state = self.state\n",
    "        return state\n",
    "    \n",
    "    def step(self, vector,data):\n",
    "        \"\"\"\n",
    "        action is vertor that cons\"i\",st of weight of s-1ocks. \n",
    "        \"\"\"\n",
    "        if self.chart_data_df.shape[0] > self.idx + 50:\n",
    "            reward,day_data = self.get_reward(vector,data)            \n",
    "            self.idx += 4\n",
    "            self.state = self.chart_data_df.iloc[self.idx:self.idx+50]\n",
    "            #print(self.state.iloc[0].name, \"~\", self.state.iloc[-1].name)\n",
    "            return self.state, reward, False, day_data\n",
    "\n",
    "        else:\n",
    "            self.idx = 0        \n",
    "            reward,day_data = self.get_reward(vector,data)\n",
    "            self.state = self.chart_data_df.iloc[self.idx:self.idx+50]\n",
    "            \n",
    "            #print(self.state.iloc[0].name, \"~\", self.state.iloc[-1].name)\n",
    "\n",
    "            return self.state, reward, False,day_data\n",
    "\n",
    "    \n",
    "    def get_reward(self, vector,data):\n",
    "        wts = vector ## factor 가중치\n",
    "        data_bind_final_sum = (self.factor_df *wts).sum(axis=1,skipna=False).to_frame()\n",
    "#         print(\"###\")\n",
    "        data_bind_final_sum.columns =['qvm']\n",
    "        port_qvm = self.data_bind.merge(data_bind_final_sum, on='종목코드')\n",
    "        port_qvm['invest'] = np.where(port_qvm['qvm'].rank() <= 20, 'Y','N')\n",
    "\n",
    "        X = port_qvm[port_qvm['invest'] == 'Y']['종목코드']\n",
    "        X = list(X)\n",
    "        #print(X)\n",
    "        reward,day_data = main2(data[X])  \n",
    "        return reward, day_data\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d310c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "# https://github.com/seungeunrho/minimalRL\n",
    "\n",
    "#PPO-LSTM\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class RECURRENT_PPO_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RECURRENT_PPO_1, self).__init__()\n",
    "        self.data = []\n",
    "\n",
    "        self.feature_num = 1629\n",
    "\n",
    "        # 일단 32개의 주식을 포트폴리오로 구성한다고 가정 \n",
    "        # when model action step, input of neural network is (stock_num * feture_per_stock) == [25 in version_0]\n",
    "        # when model train step, input of neural network is (stock_num * feature_per_stock * T_horizon) [25 * 8 = 200 in version_0]\n",
    "\n",
    "        self.fc1   = nn.Linear(64, 64)\n",
    "        self.fc2   = nn.Linear(64,128)\n",
    "        self.fc3   = nn.Linear(128,256)\n",
    "        self.fc4   = nn.Linear(256, 128)\n",
    "\n",
    "        self.lstm  = nn.LSTM(112, 64,2,batch_first=True)\n",
    "        self.lstm_1 = nn.LSTM(112,64,2,batch_first=True)\n",
    "        \n",
    "        self.fc_pi_1 = nn.Linear(64,64)\n",
    "        self.fc_pi_2   = nn.Linear(64,32)\n",
    "        self.fc_pi_3 = nn.Linear(32, 3)\n",
    "\n",
    "        self.fc_v_1 = nn.Linear(128,32)\n",
    "        self.fc_v_2  = nn.Linear(32,1)\n",
    "        learning_rate = 0.01\n",
    "        momentum = 0.99  # Momentum parameter\n",
    "\n",
    "# Create an instance of the SGD optimizer with momentum\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    def pi(self, x, hidden,previous_vector):\n",
    "        #out previous_vector\n",
    "        #print(x.shape)\n",
    "        if x.shape[0] == 50:\n",
    "            x = x.unsqueeze(0)\n",
    "        x, lstm_hidden = self.lstm(x.view(x.size(0), x.size(1), -1), hidden)\n",
    "        x = self.fc_pi_1(x[:, -1, :])\n",
    "\n",
    "        x = F.relu(self.fc_pi_1(x))\n",
    "        x = F.relu(self.fc_pi_2(x))\n",
    "        previous_vector = torch.tensor(previous_vector, dtype=torch.float32)\n",
    "        \n",
    "        x = F.relu(self.fc_pi_3(x))\n",
    "\n",
    "        weight_vector = F.softmax(x, dim=1)\n",
    "        return weight_vector, lstm_hidden\n",
    "    \n",
    "    def v(self, x, hidden):\n",
    "        \n",
    "        x, lstm_hidden = self.lstm_1(x, hidden)\n",
    "        x = x[:, -1, :] \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))        \n",
    "\n",
    "        v = self.fc_v_1(x)\n",
    "        v = self.fc_v_2(v)\n",
    "        \n",
    "        return v\n",
    "\n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "        \n",
    "\n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, h_in_lst, h_out_lst, done_lst, previous_vector_lst = [], [], [], [], [], [], [], []\n",
    "\n",
    "        print(len(self.data))\n",
    "        for transition in self.data:\n",
    "            s, a, r, s_prime, h_in, h_out, done, previous_vector = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            h_in_lst.append(h_in)\n",
    "            h_out_lst.append(h_out)\n",
    "            done_mask = 0 if done else 1\n",
    "            done_lst.append([done_mask])\n",
    "            previous_vector_lst.append([previous_vector])\n",
    "            \n",
    "        s,a,r,s_prime,done_mask, previous_vector = torch.tensor(np.array(s_lst), dtype=torch.float), torch.tensor(a_lst), \\\n",
    "                                         torch.tensor(r_lst), torch.tensor(np.array(s_prime_lst), dtype=torch.float), \\\n",
    "                                         torch.tensor(done_lst, dtype=torch.float), torch.tensor(previous_vector_lst)\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "#         print(len(s),len(a),len(r),len(s_prime), len(done_mask), len(h_in_lst[0]), len(h_out_lst[0]), len(previous_vector))\n",
    "        return s,a,r,s_prime, done_mask, h_in_lst, h_out_lst, previous_vector\n",
    "        #왜 h_in_lst[0]만 사용하지?\n",
    "    \n",
    "\n",
    "    def train_net(self):\n",
    "        \n",
    "        \n",
    "        s, a, r, s_prime, done_mask, h_in_lst, h_out_lst, previous_vector = self.make_batch()\n",
    "\n",
    "        # h_in_lst 내부의 텐서를 추출하고 적절하게 묶어서 first_hidden에 할당\n",
    "        h_in_tensors = [inner_list[0] for inner_list in h_in_lst]  # 내부 리스트의 첫 번째 요소 추출\n",
    "        first_hidden = (torch.cat([h.detach() for h in h_in_tensors], dim=1).detach(), torch.cat([h.detach() for h in h_in_tensors], dim=1).detach())\n",
    "\n",
    "        # h_out_lst 내부의 텐서를 추출하고 적절하게 묶어서 second_hidden에 할당\n",
    "        h_out_tensors = [inner_list[1] for inner_list in h_out_lst]  # 내부 리스트의 두 번째 요소 추출\n",
    "        second_hidden = (torch.cat([h.detach() for h in h_out_tensors], dim=1), torch.cat([h.detach() for h in h_out_tensors], dim=1))\n",
    "\n",
    "        # second_hidden 출력 # 2, 3, 64\n",
    "        for i in range(K_epoch_1):\n",
    "            a = self.v(s_prime,second_hidden)\n",
    "            v_prime = a.squeeze(1)\n",
    "            td_target = r + gamma_1 * v_prime\n",
    "            v_s = self.v(s,first_hidden).squeeze(1)\n",
    "            \n",
    "            delta = td_target - v_s\n",
    "            delta = delta.detach().numpy()\n",
    "\n",
    "            advantage_lst = []\n",
    "            advantage = 0.0\n",
    "            for item in delta[::-1]:\n",
    "                advantage = gamma_1 * lmbda_1 * advantage + item[0]\n",
    "                advantage_lst.append([advantage])\n",
    "            advantage_lst.reverse()\n",
    "            advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "\n",
    "            \n",
    "#             print(\"###\",s.shape, \"###\",first_hidden[0].shape, first_hidden[1].shape, \"###\",previous_vector.shape)\n",
    "            vector, _ = self.pi(s.squeeze(0), first_hidden, previous_vector) # 애초에 h_in이 policy 신경망을 통과했기 때문에 first_hidden을 사용하는 것 같음.\n",
    "            ratio = torch.exp(torch.log(vector) - torch.log(previous_vector))  # a/b == log(exp(a)-exp(b))\n",
    "\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1-eps_clip_1, 1+eps_clip_1) * advantage\n",
    "            loss = -torch.min(surr1, surr2) + F.smooth_l1_loss(v_s, td_target.detach())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward(retain_graph=True)\n",
    "            self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4f831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment2:\n",
    "    \"\"\"\n",
    "    차트 데이터는 우선 간단하게 종가와 거래량만 제공한다.\n",
    "    \"\"\"\n",
    "    \n",
    "    PRICE_IDX = 0  # 종가의 위치\n",
    "    VOLUME_IDX = 1 # 거래량의 위치\n",
    "    \"\"\"\n",
    "    version0: 아직 차트데이터에 가격밖에 없는 버전. \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, chart_data_df, feature_per_stock, balance=0, reward_method=\"return\"):\n",
    "        \"\"\"\n",
    "        chart data is n stocks that selected to portfolio\n",
    "        \"\"\"\n",
    "        self.chart_data_df = chart_data_df                                    # type(chart_data) == pd.DataFrame\n",
    "        self.feature_per_stock = feature_per_stock                      # feature per stock (i.e. close/volume)\n",
    "        self.stock_num = int(chart_data_df.shape[1] / self.feature_per_stock)   # num of stock selected for portfolio\n",
    "        self.idx = 0                                                    # index init\n",
    "        self.state = chart_data_df.iloc[self.idx]                          # state : Vector of the weight of the portfolio\n",
    "        self.next_state = chart_data_df.iloc[self.idx+1]                   # next state\n",
    "        self.reward_method = reward_method                              # set method of reward   \n",
    "        self.init_vector = np.full(self.stock_num, 1/self.stock_num)    # set init_vector of weights \n",
    "        self.portfolio_value = sum(self.state*self.init_vector)        # Portfolio growth compared to the previous day\n",
    "        self.portfolio_value_list = [self.portfolio_value]\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        initialize the all weights of portfolios equally\n",
    "        \"\"\"\n",
    "        self.idx = 0                                                    # index init\n",
    "        state = self.state\n",
    "        return state\n",
    "    \n",
    "    def step(self, vector):\n",
    "        \"\"\"\n",
    "        action is vertor that consist of weight of stocks. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.state = self.chart_data_df.iloc[self.idx]       \n",
    "            self.next_state = self.chart_data_df.iloc[self.idx+1]\n",
    "            if self.chart_data_df.shape[0] > self.idx + 1:\n",
    "                reward = self.get_reward(vector)\n",
    "                next_state = self.next_state \n",
    "                done = False\n",
    "                self.idx += 1\n",
    "                name = self.state.name\n",
    "                return next_state, reward, done, name\n",
    "        except IndexError:\n",
    "            return None, None, True, \"reset\"\n",
    "    \n",
    "    def get_reward(self, action):\n",
    "        \"\"\"\n",
    "        reward\n",
    "            - return: maximize profit of daytrading\n",
    "            - sharpe: maximize sharpe ratio\n",
    "        \"\"\"\n",
    "        if self.reward_method ==\"return\":\n",
    "            profit = sum(self.next_state * action) - self.portfolio_value_list[-1]   # in version 0, state has only close price\n",
    "            reward = self.portfolio_value_list[-1] + profit\n",
    "            self.portfolio_value_list.append(reward)\n",
    "            return reward\n",
    "\n",
    "        # not completed\n",
    "        elif self.reward_method==\"sharpe\":\n",
    "            reward = None\n",
    "            return reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0572e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4e1c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "# https://github.com/seungeunrho/minimalRL\n",
    "\n",
    "#PPO-LSTM\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class RECURRENT_PPO_2(nn.Module):\n",
    "    def __init__(self, stock_num, all_feature_num):\n",
    "        super(RECURRENT_PPO_2, self).__init__()\n",
    "        self.data = []\n",
    "\n",
    "        self.feature_num = all_feature_num\n",
    "        self.stock_num = stock_num\n",
    "\n",
    "        # 일단 32개의 주식을 포트폴리오로 구성한다고 가정 \n",
    "        # when model action step, input of neural network is (stock_num * feture_per_stock) == [25 in version_0]\n",
    "        # when model train step, input of neural network is (stock_num * feature_per_stock * T_horizon) [25 * 8 = 200 in version_0]\n",
    "        input_shape = self.feature_num * self.stock_num\n",
    "        self.lstm_2 = nn.LSTM(20,20,2)\n",
    "        self.fc1   = nn.Linear(20, 64)\n",
    "        self.fc2   = nn.Linear(64,128)\n",
    "        self.fc3   = nn.Linear(128,256)\n",
    "        self.fc4   = nn.Linear(256, 64)\n",
    "        \n",
    "        self.lstm_3  = nn.LSTM(128, 64,2)\n",
    "        \n",
    "        self.fc_pi_1 = nn.Linear(64,64)\n",
    "        self.fc_pi_2   = nn.Linear(64,stock_num)\n",
    "        self.fc_pi_3 = nn.Linear(2*stock_num, stock_num)\n",
    "\n",
    "        self.fc_v_1 = nn.Linear(64,32)\n",
    "        self.fc_v_2  = nn.Linear(32,1)\n",
    "        \n",
    "        learning_rate = 0.01\n",
    "        momentum = 0.99  # Momentum parameter\n",
    "\n",
    "# Create an instance of the SGD optimizer with momentum\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def pi(self, x, hidden, previous_vector):\n",
    "        y = self.fc1(x)\n",
    "        nan_mask = torch.isnan(y)\n",
    "        nan_values = y[nan_mask]\n",
    "        if len(nan_values) != 0:\n",
    "            print('x_-1',x)\n",
    "        x = x.view(-1, 1, 20)\n",
    "        x,lstm_hidden= self.lstm_2(x,hidden)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        nan_mask = torch.isnan(x)\n",
    "        nan_values = x[nan_mask]\n",
    "        if len(nan_values) != 0:\n",
    "            print('x_--1',x)\n",
    "        x = F.relu(x)\n",
    "        nan_mask = torch.isnan(x)\n",
    "        nan_values = x[nan_mask]\n",
    "        if len(nan_values) != 0:\n",
    "            print('x_0',x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "       # x, lstm_hidden = self.lstm_3(x, hidden)\n",
    "\n",
    "        nan_mask = torch.isnan(x)\n",
    "        nan_values = x[nan_mask]\n",
    "        if len(nan_values) != 0:\n",
    "            print('x_1',x)\n",
    "        x = F.relu(self.fc_pi_1(x))\n",
    "        x = F.relu(self.fc_pi_2(x))\n",
    "        \n",
    "        previous_vector = torch.tensor(previous_vector, dtype=torch.float32)\n",
    "        \n",
    "        x = torch.concat([x, previous_vector.view(-1,1,self.stock_num)], 2)\n",
    "        x = F.relu(self.fc_pi_3(x))\n",
    "        nan_mask = torch.isnan(x)\n",
    "        nan_values = x[nan_mask]\n",
    "        if len(nan_values) != 0:\n",
    "            print('x',x)\n",
    "        weight_vector = F.softmax(x, dim=2)\n",
    "\n",
    "        return weight_vector, lstm_hidden\n",
    "\n",
    "    def v(self, x, hidden):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        v = self.fc_v_1(x)\n",
    "        \n",
    "        \n",
    "        return v\n",
    "\n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "\n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, h_in_lst, h_out_lst, done_lst, previous_vector_lst = [], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "        for transition in self.data:\n",
    "            s, a, r, s_prime, h_in, h_out, done, previous_vector = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            h_in_lst.append(h_in)\n",
    "            h_out_lst.append(h_out)\n",
    "            done_mask = 0 if done else 1\n",
    "            done_lst.append([done_mask])\n",
    "            previous_vector_lst.append([previous_vector])\n",
    "            \n",
    "        s,a,r,s_prime,done_mask, previous_vector = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "                                         torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "                                         torch.tensor(done_lst, dtype=torch.float), torch.tensor(previous_vector_lst)\n",
    "        \n",
    "        self.data = []\n",
    "        return s,a,r,s_prime, done_mask, h_in_lst[0], h_out_lst[0], previous_vector\n",
    "\n",
    "    def train_net(self):\n",
    "        s,a,r,s_prime,done_mask,(h1_in, h2_in), (h1_out, h2_out),previous_vector  = self.make_batch()\n",
    "        first_hidden  = (h1_in.detach(), h2_in.detach())\n",
    "        second_hidden = (h1_out.detach(), h2_out.detach())\n",
    "        \n",
    "        \n",
    "        for i in range(K_epoch_2):\n",
    "            v_prime = self.v(s_prime, second_hidden).squeeze(1)\n",
    "            td_target = r + gamma_2 * v_prime * done_mask\n",
    "            v_s = self.v(s, first_hidden).squeeze(1)\n",
    "            delta = td_target - v_s\n",
    "            delta = delta.detach().numpy()\n",
    "\n",
    "            advantage_lst = []\n",
    "            advantage = 0.0\n",
    "            for item in delta[::-1]:\n",
    "                advantage = gamma_2 * lmbda_2 * advantage + item[0]\n",
    "                advantage_lst.append([advantage])\n",
    "            advantage_lst.reverse()\n",
    "            advantage = torch.tensor(advantage_lst, dtype=torch.float)\n",
    "\n",
    "            \n",
    "\n",
    "            vector, _ = self.pi(s, first_hidden, previous_vector) # 애초에 h_in이 policy 신경망을 통과했기 때문에 first_hidden을 사용하는 것 같음.\n",
    "            ratio = torch.exp(torch.log(vector) - torch.log(previous_vector))  # a/b == log(exp(a)-exp(b))\n",
    "\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1-eps_clip_2, 1+eps_clip_2) * advantage\n",
    "            loss = -torch.min(surr1, surr2) + F.smooth_l1_loss(v_s, td_target.detach())\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward(retain_graph=True)\n",
    "            self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12449612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "gamma_2        = 0.98\n",
    "lmbda_2        = 0.95\n",
    "eps_clip_2      = 0.1\n",
    "K_epoch_2      = 4\n",
    "\n",
    "count = 0\n",
    "def main2(chart_data):\n",
    "    stock_num = 20\n",
    "    T_horizon  = 50\n",
    "    env = Environment2(chart_data_df=chart_data, feature_per_stock=1)\n",
    "    model = RECURRENT_PPO_2(stock_num=20, all_feature_num=20*1)\n",
    "    score = 0.0\n",
    "    epi_range = 10\n",
    "    \n",
    "    score_list = []\n",
    "    print_interval = 12\n",
    "    day_list = []\n",
    "    score_list_1 = []\n",
    "    day_list_1 = []\n",
    "\n",
    "    for n_epi in range(epi_range):\n",
    "        h_out = (torch.zeros([2, 1, 20], dtype=torch.float), torch.zeros([2, 1, 20], dtype=torch.float))\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "        previous_vector = np.full(stock_num, 1/stock_num)\n",
    "\n",
    "        for t in range(T_horizon):\n",
    "                #print('s',s)\n",
    "                h_in = h_out\n",
    "                vector, h_out = model.pi(torch.tensor(s, dtype=torch.float32), h_in, previous_vector)\n",
    "                #print('vector',vector)\n",
    "                vector = vector.view(-1)\n",
    "                vector = vector.detach().numpy()\n",
    "\n",
    "                s_prime, r, done, name = env.step(vector)\n",
    "                #print(\"r,enpi:\",r,n_epi)\n",
    "                if not done:\n",
    "                    model.put_data((s, vector, r, s_prime, h_in, h_out, done, previous_vector))\n",
    "                    s = s_prime\n",
    "                    previous_vector = vector\n",
    "                    score += r\n",
    "                    score_list_1.append([score,0])\n",
    "                #print(\"주식별 가중치:\\n\", vector)\n",
    "                \n",
    "                if done:\n",
    "                    s = env.reset()\n",
    "                    break\n",
    "        day_list.append(score_list_1)\n",
    "        #print(score)\n",
    "        score_list.append(score/70)\n",
    "            \n",
    "        score = 0.0\n",
    "        model.train_net()\n",
    "        #print(\"model1 score:\",score)\n",
    "    day_list_1.append(score_list_1)\n",
    "    \n",
    "    \n",
    "    #print(\"model2 avg score:\", sum(score_list)/epi_range)\n",
    "    #print()\n",
    "    #plt.plot(score_list)\n",
    "    #plt.show()\n",
    "    return sum(score_list)/epi_range, day_list_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7335fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "#Hyperparameters\n",
    "learning_rate_1 = 0.0005\n",
    "gamma_1         = 0.98\n",
    "lmbda_1         = 0.95\n",
    "eps_clip_1      = 0.1\n",
    "K_epoch_1       = 7\n",
    "T_horizon_1     = 2\n",
    "score_list_all_1 = []\n",
    "\n",
    "def main1():\n",
    "    env = Environment1(chart_data_df =df_per.loc['2023-01-30'::].iloc[:100], feature_per_stock=1)\n",
    "    model = RECURRENT_PPO_1()\n",
    "    score = 0.0\n",
    "    score_list = []\n",
    "    print_interval = 12\n",
    "    day_data_0 = []\n",
    "    day_data_1 = []\n",
    "    day_data_2 = []\n",
    "    \n",
    "    for n_epi in tqdm(range(10)):\n",
    "        h_out = (torch.zeros([2, 1, 64], dtype=torch.float), torch.zeros([2, 1, 64], dtype=torch.float))\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "        previous_vector = np.array([0.1,0.5,0.4])\n",
    "        \n",
    "        for t in range(T_horizon_1):\n",
    "            h_in = h_out\n",
    "            vector, h_out = model.pi(torch.tensor(s.values, dtype = torch.float), h_in,previous_vector)#out previous_vector\n",
    "            vector = vector.view(-1)\n",
    "            vector = vector.detach().numpy()\n",
    "            s_prime, r, done, day_data = env.step(vector, s)\n",
    "\n",
    "#           print(\"31번째 줄\")\n",
    "            model.put_data((s, vector, r, s_prime, h_in, h_out, done,previous_vector))#out previous_vector\n",
    "            s = s_prime\n",
    "            previous_vector = vector\n",
    "            score += r\n",
    "            score_list.append(r)\n",
    "#            print(\"38번째 줄\")\n",
    "#                 break\n",
    "#         print(\"43번째 줄\")\n",
    "            day_data_0.append(day_data)\n",
    "        \n",
    "        plt.plot(score_list)\n",
    "        plt.show()\n",
    "        model.train_net()\n",
    "        day_data_1.append(day_data_0)\n",
    "        print(sum(score_list)/T_horizon_1)\n",
    "        print(\"episode:\",n_epi)\n",
    "        score_list_all.append(sum(score_list)/T_horizon_1)\n",
    "        score = 0.0\n",
    "        score_list = []\n",
    "    day_data_2.append(day_data_1)\n",
    "    return day_data_2\n",
    "if __name__ == '__main__':\n",
    "    a = main1()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"{end - start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf13334",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a[0][0][0][0])\n",
    "#[의미없음][모델2의 Epoch][의미없음][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6dd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(score_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9309b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc33f6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901e386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45017a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromson_test",
   "language": "python",
   "name": "fromson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
